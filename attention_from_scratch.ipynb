{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dcc6d3e",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e57ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3feeb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fc027",
   "metadata": {},
   "source": [
    "## Simplified Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a09d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our goal is to calculate the context vector using the current query vector and the given sequence\n",
    "# We are considering a input sentence \"Your journey starts with one step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e788f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "[[0.43, 0.15, 0.89], # Your (x^1)\n",
    "[0.55, 0.87, 0.66], # journey (x^2)\n",
    "[0.57, 0.85, 0.64], # starts (x^3)\n",
    "[0.22, 0.58, 0.33], # with (x^4)\n",
    "[0.77, 0.25, 0.10], # one (x^5)\n",
    "[0.05, 0.80, 0.55]] # step (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858f970",
   "metadata": {},
   "source": [
    "#### Calculate Attention Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc9cd1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "\n",
    "# Calculate the attention score for each token w.r.t query token\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(query, x_i)\n",
    "print(attn_scores_2)\n",
    "\n",
    "\n",
    "\n",
    "# # torch.dot function can also be implemented using following way\n",
    "# # Dot product is way of multiplying two vectors element-wise and then summing the product \n",
    "# attn_scores_2_brute = torch.empty(inputs.shape[0])\n",
    "# for i, x_i in enumerate(inputs):                # at i = 0 - x_i = [0.43, 0.15, 0.89], query = [0.55, 0.87, 0.66]\n",
    "#     temp_attn = 0\n",
    "#     for j, x_i_i in enumerate(x_i):             # at i = 0 and j = 0 , x_i_i = 0.43, query[j] = query[0] = 0.55\n",
    "#         temp_attn += query[j] * x_i_i\n",
    "#     attn_scores_2_brute[i] = temp_attn\n",
    "# print(attn_scores_2_brute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a122d",
   "metadata": {},
   "source": [
    "#### Normalize the attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab69ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46feda52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456dcf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be11dfc",
   "metadata": {},
   "source": [
    "#### Calculate Context Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0508447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd792c",
   "metadata": {},
   "source": [
    "#### Putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd16393a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attn_scores_tm = torch.empty(6,6)\n",
    "# for i, x_i in enumerate(inputs):\n",
    "#     for j, x_j in enumerate(inputs):\n",
    "#         attn_scores_tm[i,j] = torch.dot(x_i, x_j)\n",
    "\n",
    "# print(attn_scores_tm)\n",
    "\n",
    "\n",
    "\n",
    "# The better way of doing it is \n",
    "\n",
    "attn_scores = inputs @ inputs.T\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9674da10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=-1)     # Here we are keeping dim=-1 so that it should normalize values on column level.\n",
    "                                                                # If normalize values based on column then on row level the sum will be 1\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6edf2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89765024",
   "metadata": {},
   "source": [
    "## Self-Attention with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea1b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "[[0.43, 0.15, 0.89], # Your (x^1)\n",
    "[0.55, 0.87, 0.66], # journey (x^2)\n",
    "[0.57, 0.85, 0.64], # starts (x^3)\n",
    "[0.22, 0.58, 0.33], # with (x^4)\n",
    "[0.77, 0.25, 0.10], # one (x^5)\n",
    "[0.05, 0.80, 0.55]] # step (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81354b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5500, 0.8700, 0.6600])\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "print(x_2)\n",
    "print(d_in)\n",
    "print(d_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7059c",
   "metadata": {},
   "source": [
    "#### Computing the attention weights step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5bacab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in,d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in,d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in,d_out), requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "533ce51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36d17e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5707b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the attention score for w22 \n",
    "keys_2 = keys[1]\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c3f03d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00bf4c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "184d3b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b4a5c",
   "metadata": {},
   "source": [
    "#### Self-attention python class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3018febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_k = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_q = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_v = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x - (6, 3)\n",
    "        keys = x @ self.W_k # 6,3 @ 3, 2 -> 6,2 \n",
    "        values = x @ self.W_v # 6,3 @ 3, 2 -> 6,2 \n",
    "        queries = x @ self.W_q # 6,3 @ 3, 2 -> 6,2 \n",
    "\n",
    "        attn_scores = queries @ keys.T # 6, 2 @ 2, 6\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0333f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2947, 0.7956],\n",
      "        [0.3015, 0.8132],\n",
      "        [0.3010, 0.8120],\n",
      "        [0.2925, 0.7902],\n",
      "        [0.2863, 0.7737],\n",
      "        [0.2979, 0.8043]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eefb220f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3377, -0.2826],\n",
      "        [-0.3369, -0.2830],\n",
      "        [-0.3369, -0.2829],\n",
      "        [-0.3367, -0.2833],\n",
      "        [-0.3372, -0.2825],\n",
      "        [-0.3365, -0.2835]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias='qkv_bias')\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias='qkv_bias')\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias='qkv_bias')\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_k(x)\n",
    "        queries = self.W_q(x)\n",
    "        values = self.W_v(x)\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        context_vectors = attn_weights @ values\n",
    "        return context_vectors\n",
    "\n",
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9d1b2",
   "metadata": {},
   "source": [
    "## Self Attention with Causal Masking and Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17df178",
   "metadata": {},
   "source": [
    "#### Using simpler masking (torch.tril)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8320d816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4559, -0.5804, -0.5755, -0.4223, -0.3861, -0.4831],\n",
      "        [-0.3016, -0.4029, -0.4003, -0.3148, -0.2953, -0.3471],\n",
      "        [-0.2871, -0.3840, -0.3816, -0.3005, -0.2820, -0.3311],\n",
      "        [-0.4552, -0.6044, -0.6003, -0.4682, -0.4379, -0.5185],\n",
      "        [-0.1038, -0.1428, -0.1421, -0.1161, -0.1104, -0.1255],\n",
      "        [-0.5841, -0.7729, -0.7676, -0.5957, -0.5562, -0.6614]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[0.1698, 0.1555, 0.1560, 0.1739, 0.1784, 0.1665],\n",
      "        [0.1716, 0.1598, 0.1600, 0.1700, 0.1724, 0.1662],\n",
      "        [0.1714, 0.1601, 0.1604, 0.1698, 0.1721, 0.1662],\n",
      "        [0.1736, 0.1562, 0.1566, 0.1720, 0.1757, 0.1660],\n",
      "        [0.1690, 0.1644, 0.1645, 0.1675, 0.1682, 0.1664],\n",
      "        [0.1751, 0.1532, 0.1538, 0.1736, 0.1786, 0.1658]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_q(inputs)\n",
    "keys = sa_v2.W_k(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "print(attn_scores)\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66299386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1698, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1716, 0.1598, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1714, 0.1601, 0.1604, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1736, 0.1562, 0.1566, 0.1720, 0.0000, 0.0000],\n",
       "        [0.1690, 0.1644, 0.1645, 0.1675, 0.1682, 0.0000],\n",
       "        [0.1751, 0.1532, 0.1538, 0.1736, 0.1786, 0.1658]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row sums shape: torch.Size([6, 1])\n",
      "tensor([[0.1698],\n",
      "        [0.3314],\n",
      "        [0.4919],\n",
      "        [0.6583],\n",
      "        [0.8336],\n",
      "        [1.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5179, 0.4821, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3485, 0.3255, 0.3260, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2636, 0.2372, 0.2379, 0.2612, 0.0000, 0.0000],\n",
       "        [0.2027, 0.1972, 0.1973, 0.2010, 0.2018, 0.0000],\n",
       "        [0.1751, 0.1532, 0.1538, 0.1736, 0.1786, 0.1658]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mask which mark diagonal elements as 0\n",
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask_simple)\n",
    "\n",
    "# Multiple the atten_weights to remove the future elements\n",
    "masked_simple = attn_weights * mask_simple\n",
    "display(masked_simple)\n",
    "\n",
    "# Normalize the values\n",
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "print(f\"row sums shape: {row_sums.shape}\")\n",
    "print(row_sums)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "masked_simple_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92bc993",
   "metadata": {},
   "source": [
    "#### Using -inf (torch.triu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "47dd947c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[[-0.0696,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "         [-0.0655, -0.0646,    -inf,    -inf,    -inf,    -inf],\n",
      "         [-0.0593, -0.0528, -0.0505,    -inf,    -inf,    -inf],\n",
      "         [-0.0476, -0.0653, -0.0640, -0.0372,    -inf,    -inf],\n",
      "         [ 0.0680,  0.1742,  0.1745,  0.0978,  0.1304,    -inf],\n",
      "         [-0.1090, -0.1804, -0.1783, -0.1022, -0.0891, -0.1296]],\n",
      "\n",
      "        [[-0.0696,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "         [-0.0655, -0.0646,    -inf,    -inf,    -inf,    -inf],\n",
      "         [-0.0593, -0.0528, -0.0505,    -inf,    -inf,    -inf],\n",
      "         [-0.0476, -0.0653, -0.0640, -0.0372,    -inf,    -inf],\n",
      "         [ 0.0680,  0.1742,  0.1745,  0.0978,  0.1304,    -inf],\n",
      "         [-0.1090, -0.1804, -0.1783, -0.1022, -0.0891, -0.1296]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "print(mask)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4681ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5179, 0.4821, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3485, 0.3255, 0.3260, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2636, 0.2372, 0.2379, 0.2612, 0.0000, 0.0000],\n",
      "        [0.2027, 0.1972, 0.1973, 0.2010, 0.2018, 0.0000],\n",
      "        [0.1751, 0.1532, 0.1538, 0.1736, 0.1786, 0.1658]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3b58b",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc73e2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n",
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6971, 0.6509, 0.6520, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4745, 0.4758, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3944, 0.0000, 0.4019, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3064, 0.3075, 0.3473, 0.3571, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(dropout(example))\n",
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db9755",
   "metadata": {},
   "source": [
    "#### Batch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29b766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([6, 3])\n",
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inputs shape: {inputs.shape}\")\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f4ab5",
   "metadata": {},
   "source": [
    "#### Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "09b235a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_in: 3 \n",
      " d_out: 2 \n",
      " context_length: 6\n",
      "Dimensions of w metrices are: Linear(in_features=3, out_features=2, bias=False)\n",
      "Shape of mask is : torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "# Stacking the same input twice to create a batch\n",
    "batched_inputs = torch.stack((inputs, inputs), dim=0)\n",
    "d_in = batched_inputs.shape[2]\n",
    "d_out = 2\n",
    "context_length = batched_inputs.shape[1]\n",
    "\n",
    "print(f\"d_in: {d_in} \\n d_out: {d_out} \\n context_length: {context_length}\")\n",
    "\n",
    "w_query = nn.Linear(d_in, d_out, bias=False)\n",
    "w_key = nn.Linear(d_in, d_out, bias=False)\n",
    "w_value = nn.Linear(d_in, d_out, bias=False)\n",
    "print(f\"Dimensions of w metrices are: {w_query}\")\n",
    "\n",
    "# Number of elements to erase from the given matrix\n",
    "dropout = nn.Dropout(0.5)\n",
    "\n",
    "# Creating this mask for causal attntion so that only previous and current token so that relvancy with only previous and current token is available\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "print(f\"Shape of mask is : {mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c512ae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of w_query:\n",
      " Parameter containing:\n",
      "tensor([[-0.3976,  0.1673,  0.2912],\n",
      "        [-0.3153,  0.0842, -0.2289]], requires_grad=True)\n",
      "Bias of w_query:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights of w_query:\\n\", w_query.weight)\n",
    "print(\"Bias of w_query:\\n\", w_query.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd3007bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 2])\n",
      "torch.Size([2, 6, 2])\n",
      "torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "b, num_tokens, d_in = batched_inputs.shape\n",
    "\n",
    "# Getting the q,k,v matrices from q,k,v matrices\n",
    "# This is done by multiplying batched_inputs with w_key weights\n",
    "keys = w_key(batched_inputs)\n",
    "values = w_value(batched_inputs)\n",
    "queries = w_query(batched_inputs)\n",
    "# display((batched_inputs @ w_key.weight.T)==(w_key(batched_inputs))) # True\n",
    "\n",
    "print(keys.shape)\n",
    "print(values.shape)\n",
    "print(queries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dbc40fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 2])\n",
      "torch.Size([2, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "print(keys.shape)\n",
    "print(keys.transpose(1,2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c033c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the printed mask.bool(). Basically mask.bool() tells at which places to fill -torch.inf\n",
    "mask.bool()[:num_tokens, :num_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07aba3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_scores shape: torch.Size([2, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0696,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "         [-0.0655, -0.0646,    -inf,    -inf,    -inf,    -inf],\n",
       "         [-0.0593, -0.0528, -0.0505,    -inf,    -inf,    -inf],\n",
       "         [-0.0476, -0.0653, -0.0640, -0.0372,    -inf,    -inf],\n",
       "         [ 0.0680,  0.1742,  0.1745,  0.0978,  0.1304,    -inf],\n",
       "         [-0.1090, -0.1804, -0.1783, -0.1022, -0.0891, -0.1296]],\n",
       "\n",
       "        [[-0.0696,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "         [-0.0655, -0.0646,    -inf,    -inf,    -inf,    -inf],\n",
       "         [-0.0593, -0.0528, -0.0505,    -inf,    -inf,    -inf],\n",
       "         [-0.0476, -0.0653, -0.0640, -0.0372,    -inf,    -inf],\n",
       "         [ 0.0680,  0.1742,  0.1745,  0.0978,  0.1304,    -inf],\n",
       "         [-0.1090, -0.1804, -0.1783, -0.1022, -0.0891, -0.1296]]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Focus that we are only transposing 2nd and 3rd dimensions of the key vectors\n",
    "attn_scores = queries @ keys.transpose(1,2) # [2,6,2] @ [2, 2, 6] --> [2, 6, 6]\n",
    "print(f\"attn_scores shape: {attn_scores.shape}\")\n",
    "\n",
    "attn_scores.masked_fill_(mask.bool(), -torch.inf)\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6f8b401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4998, 0.5002, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3321, 0.3337, 0.3342, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2510, 0.2479, 0.2481, 0.2529, 0.0000, 0.0000],\n",
       "        [0.1915, 0.2064, 0.2064, 0.1956, 0.2001, 0.0000],\n",
       "        [0.1693, 0.1609, 0.1612, 0.1701, 0.1717, 0.1668]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0003, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.6643, 0.6673, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5021, 0.4958, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4128, 0.0000, 0.3911, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3219, 0.0000, 0.0000, 0.0000, 0.3337]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)  # Here we are applying softmax function of dim=-1 i.e. column level so that total sum of all values in rows will be 1\n",
    "\n",
    "display(attn_weights[0])\n",
    "# Applying dropout\n",
    "attn_weights = dropout(attn_weights)\n",
    "display(attn_weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266178d2",
   "metadata": {},
   "source": [
    "#### Causal Attention with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d07572b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in: int, d_out: int, context_length: int, dropout: float, qkv_bias: bool = False):\n",
    "        super().__init__()\n",
    "        # Intialise the weight matrices which will trainable\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        # Initialize the droput layer to drop certail tensors. Used only while training\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Mask for Causal attention\n",
    "        self.mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        queries = self.W_query(input) # 2 ,6 ,2 \n",
    "        keys = self.W_key(input)# 2 ,6 ,2 \n",
    "        values = self.W_value(input)# 2 ,6 ,2 \n",
    "\n",
    "        # Calculate the attention scores by matmul of queries and keys\n",
    "        # Important thing to note here is that we are only tranposing last two dimensions of key matrix\n",
    "        attn_scores = queries @ keys.transpose(-2,-1)\n",
    "\n",
    "        # Apply causal attention mask to the attn_scores\n",
    "        # In pytorch, _ at the end of function denotes inplace operation\n",
    "        # we are converting the mask into bool. Basically identifying the places where we have to fill -infinity\n",
    "        # For more details check putting all together implementation\n",
    "        attn_scores.masked_fill_(self.mask.bool(), -torch.inf)\n",
    "\n",
    "        # Calculate attention weights\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1) #  Here we are normalizing values at -1 i.e. column level. So that sum of each row should add up to 1.\n",
    "\n",
    "        # Dropout random tensors\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Calculate context vectors\n",
    "        context_vector = attn_weights @ values \n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82656a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([6, 3])\n",
      "torch.Size([2, 6, 3])\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(f\"Inputs shape: {inputs.shape}\")\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8fc20",
   "metadata": {},
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebfaf40",
   "metadata": {},
   "source": [
    "### MHA Wrapper using self attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08493ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_rev(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias='qkv_bias')\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias='qkv_bias')\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias='qkv_bias')\n",
    "\n",
    "        self.mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "\n",
    "        masked_attn_scores = attn_scores.masked_fill(self.mask.bool(), -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(masked_attn_scores / keys.shape[1]**0.5, dim=-1)\n",
    "\n",
    "        context_vectors = attn_weights @ values\n",
    "\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_rev(d_in, d_out, inputs.shape[0])\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e982f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_rev(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias) # \n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, num_tokens, d_in = x.shape\n",
    "\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1,2)\n",
    "        attn_scores.masked_fill_(mask.bool()[:num_tokens,:num_tokens], -torch.inf)\n",
    "\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vectors = attn_weights @ values\n",
    "\n",
    "        return context_vectors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63b84e",
   "metadata": {},
   "source": [
    "### MHA optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17111dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1378, -0.4154],\n",
      "        [-0.2589, -0.3110],\n",
      "        [-0.2976, -0.2762],\n",
      "        [-0.3150, -0.2884],\n",
      "        [-0.3409, -0.2551],\n",
      "        [-0.3426, -0.2714]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
